{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b85fe7b-cd51-4a14-8079-2a6146d72adf",
   "metadata": {},
   "source": [
    "# CS 224N - WinoDict Evaluation using RoBERTa Embeddings\n",
    "Evaluating on WinoDict task using RoBERTa finetuned to predict GPT-2 embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be948f-5392-44a7-b250-597527e3f474",
   "metadata": {},
   "source": [
    "## Setting up PyTorch\n",
    "Using PyTorch on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b013644-fe9c-4c94-bc13-4d28c4a6c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using GPU: \" + str(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edda494-e0d9-4d00-88e3-3869f8392c33",
   "metadata": {},
   "source": [
    "## Load in WinoDict Dataset\n",
    "Load in the first generated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6e85f1-5074-4788-8b3c-a3e0f6f7b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first_set = pd.read_csv(\"winodict/prob1_of_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9e2fa-2789-429b-8f33-1ffb84805e37",
   "metadata": {},
   "source": [
    "## Check Definitions of Words in Wordset\n",
    "With old Wordset dataset, check if they end up existing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094721d5-ff36-43e7-a4e0-320e5d3a3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_definition(word):\n",
    "    # Load in the data for the first letter\n",
    "    letter = word[0]\n",
    "    f = open('dictionary/' + letter + '.json')\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # Look through each of the definitions\n",
    "    definition = \"\"\n",
    "    if (word in data.keys()):\n",
    "        if ('meanings' in data[word]):\n",
    "            for index in range(len(data[word]['meanings'])):\n",
    "                definition += data[word]['meanings'][index]['def'] + \". \"\n",
    "    \n",
    "    return definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f95df8-4330-4898-8f61-2dd05e6bf33e",
   "metadata": {},
   "source": [
    "## Helper Function to Add CLS Token\n",
    "Add a CLS token to function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945188ce-16af-4fa8-a690-a22a448f7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_initial_cls(tokenizer, model):\n",
    "    # Add CLS token\n",
    "    tokenizer.add_tokens(['[CLS]'])\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # Get all the pre-expansion embeddings\n",
    "    params = model.state_dict()\n",
    "    embeddings = params['transformer.wte.weight']\n",
    "    pre_expansion_embeddings = embeddings[:-1,:]\n",
    "    \n",
    "    # Calculate mean, sigma, n\n",
    "    mu = torch.mean(pre_expansion_embeddings, dim=0)\n",
    "    n = pre_expansion_embeddings.size()[0]\n",
    "    sigma = ((pre_expansion_embeddings - mu).T @ (pre_expansion_embeddings - mu)) / n\n",
    "    \n",
    "    # Calculate the distribution\n",
    "    dist = torch.distributions.multivariate_normal.MultivariateNormal(\n",
    "            mu, covariance_matrix=1e-5*sigma)\n",
    "    \n",
    "    # Load in the new embedding for the CLS token\n",
    "    new_embeddings = torch.stack(tuple((dist.sample() for _ in range(1))), dim=0)\n",
    "    embeddings[-1:,:] = new_embeddings\n",
    "    params['transformer.wte.weight'][-1:,:] = new_embeddings\n",
    "    model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21809b-a2f7-4c40-8a69-69683a08f207",
   "metadata": {},
   "source": [
    "## Grab GPT-2 and RoBERTa\n",
    "Look at GPT-2 and RoBERTa fine-tuned for downstream task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4427bc2a-0605-42b2-9b15-5d46dc31753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, RobertaModel\n",
    "\n",
    "# GPT-2 Model and Tokenizer\n",
    "ro_model = GPT2LMHeadModel.from_pretrained(\"weights/wordnetepoch1\")\n",
    "ro_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "add_initial_cls(ro_tokenizer, ro_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a913fd-ed9a-47be-81e8-df415ddce4e5",
   "metadata": {},
   "source": [
    "## Turning Fake Words into Embeddings in GPT-2!\n",
    "Using a standard GPT-2 model, added the new word embedding specifically for the fake word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31a8c6c-9cf1-42ab-963b-20d8e8d73868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_word_into_embedding(replacement, fake_word):\n",
    "    # GPT-2 Model and Tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "    \n",
    "    # Get definition of the word\n",
    "    definition = find_definition(replacement)\n",
    "    \n",
    "    # Adding the next word\n",
    "    if (definition != \"\"):\n",
    "        # Pass into the tokenizer\n",
    "        ro_tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenized_input = ro_tokenizer(definition, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=511)\n",
    "        tokenized_cls = ro_tokenizer(\" [CLS]\", return_tensors=\"pt\")\n",
    "        tokenized_input['input_ids'] = torch.cat((tokenized_input['input_ids'], tokenized_cls['input_ids']), dim=1)\n",
    "        \n",
    "        # Pass into the model and extract the predicted embedding\n",
    "        outputs = ro_model(input_ids=tokenized_input['input_ids'], output_hidden_states=True)\n",
    "        last_hidden = outputs.hidden_states[-1][:,511,:]\n",
    "        predicted_embedding = last_hidden.squeeze(0)\n",
    "        \n",
    "        # Add the new token and resize the model embedding\n",
    "        tokenizer.add_tokens([fake_word])\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        # Get model parameters and embeddings\n",
    "        params = model.state_dict()\n",
    "        embeddings = params['transformer.wte.weight']\n",
    "        \n",
    "        # Update with the new embedding\n",
    "        embeddings[-1:,:] = predicted_embedding\n",
    "        params['transformer.wte.weight'][-1:,:] = predicted_embedding\n",
    "        model.load_state_dict(params)\n",
    "    \n",
    "    # Done!\n",
    "    print(\"Finished with creating the new model and tokenizer\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64f00f-e123-480c-b8c4-b2e32f6d5a24",
   "metadata": {},
   "source": [
    "## Evaluating WinoDict on One Example\n",
    "Writing a function that is reusable and works for one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d392d63-b221-4898-ade9-11a8e0293805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_winodict(example):\n",
    "    # First, replace the word with each of the options\n",
    "    if ('_' in example['sentence']):\n",
    "        # Get the correct evaluation model\n",
    "        model, tokenizer = fake_word_into_embedding(example['lemma'], example['fake_lemma'])\n",
    "        \n",
    "        # Change 'the' to lowercase\n",
    "        first_choice, second_choice = example['option1'], example['option2']\n",
    "        if (first_choice[:4] == \"The \"):\n",
    "            first_choice = \"the \" + first_choice[4:]\n",
    "        if (second_choice[:4] == \"The \"):\n",
    "            second_choice = \"the \" + second_choice[4:]\n",
    "\n",
    "        # Replace the text\n",
    "        first_text, second_text = example['sentence'], example['sentence']\n",
    "        pronoun_loc = example['sentence'].index('_')\n",
    "        first_option = example['definition'] + \" \" + first_text[:pronoun_loc] + first_choice + first_text[pronoun_loc + 1:]\n",
    "        second_option = example['definition'] + \" \" + second_text[:pronoun_loc] + second_choice + second_text[pronoun_loc + 1:]\n",
    "\n",
    "        # Tokenize each string and produce labels\n",
    "        first_inputs, second_inputs = tokenizer(first_option, return_tensors=\"pt\"), tokenizer(second_option, return_tensors=\"pt\")\n",
    "\n",
    "        # Create the first token labels\n",
    "        first_masked_tokens = tokenizer(example['definition'] + \" \" + first_text[:pronoun_loc] + first_choice, return_tensors=\"pt\")\n",
    "        first_labels = first_masked_tokens[\"input_ids\"][0]\n",
    "        first_mask = torch.full((1, first_labels.shape[0]), -100)\n",
    "        first_fill = tokenizer(first_text[pronoun_loc + 1:], return_tensors=\"pt\")[\"input_ids\"]\n",
    "        final_first_labels = torch.cat((first_mask, first_fill), dim=1)\n",
    "\n",
    "        # Create the second token labels\n",
    "        second_masked_tokens = tokenizer(example['definition'] + \" \" + second_text[:pronoun_loc] + second_choice, return_tensors=\"pt\")\n",
    "        second_labels = second_masked_tokens[\"input_ids\"][0]\n",
    "        second_mask = torch.full((1, second_labels.shape[0]), -100)\n",
    "        second_fill = tokenizer(second_text[pronoun_loc + 1:], return_tensors=\"pt\")[\"input_ids\"]\n",
    "        final_second_labels = torch.cat((second_mask, second_fill), dim=1)\n",
    "\n",
    "        # Evaluate the model on each example and check\n",
    "        first_loss = model(**first_inputs, labels=final_first_labels).loss\n",
    "        second_loss = model(**second_inputs, labels=final_second_labels).loss\n",
    "        \n",
    "        # Write down the correct value and check\n",
    "        if (first_loss < second_loss):\n",
    "            print(\"Finished Evaluation\")\n",
    "            return (int(example['label']) == 0)\n",
    "        else:\n",
    "            print(\"Finished Evaluation\")\n",
    "            return (int(example['label']) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f58a5-d491-429c-9a3e-66a78766f67a",
   "metadata": {},
   "source": [
    "## Evaluating Winograd on GPT-2\n",
    "Looking specifically at `WinoDict`, with the first generated examples and adding in the definition and substituting in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd9783-aaab-4cc4-8894-4a9faac71c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "0\n",
      "1\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "0\n",
      "2\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "1\n",
      "3\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "1\n",
      "4\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "1\n",
      "5\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "2\n",
      "6\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "3\n",
      "7\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "3\n",
      "8\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "3\n",
      "9\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "4\n",
      "10\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "5\n",
      "11\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "5\n",
      "12\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "6\n",
      "13\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "6\n",
      "14\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "6\n",
      "15\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "7\n",
      "16\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "8\n",
      "17\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "9\n",
      "18\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "9\n",
      "19\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "10\n",
      "20\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "10\n",
      "21\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "11\n",
      "22\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "12\n",
      "23\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "13\n",
      "24\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "13\n",
      "25\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "14\n",
      "26\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "15\n",
      "27\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "15\n",
      "28\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "16\n",
      "29\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "16\n",
      "30\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "16\n",
      "31\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "17\n",
      "32\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "17\n",
      "33\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "18\n",
      "34\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "18\n",
      "35\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "19\n",
      "36\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "20\n",
      "37\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "20\n",
      "38\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "21\n",
      "39\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "22\n",
      "40\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "23\n",
      "41\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "23\n",
      "42\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "23\n",
      "43\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "24\n",
      "44\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "24\n",
      "45\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "25\n",
      "46\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "26\n",
      "47\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "26\n",
      "48\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "26\n",
      "49\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "27\n",
      "50\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "28\n",
      "51\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "28\n",
      "52\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "28\n",
      "53\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "29\n",
      "54\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "30\n",
      "55\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "30\n",
      "56\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "30\n",
      "57\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "31\n",
      "58\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "32\n",
      "59\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "32\n",
      "60\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "32\n",
      "61\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "33\n",
      "62\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "34\n",
      "63\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "34\n",
      "64\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "35\n",
      "65\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "35\n",
      "66\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "35\n",
      "67\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "36\n",
      "68\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "37\n",
      "69\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "38\n",
      "70\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "39\n",
      "71\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "39\n",
      "72\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "40\n",
      "73\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "40\n",
      "74\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "40\n",
      "75\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "41\n",
      "76\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "41\n",
      "77\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "42\n",
      "78\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "42\n",
      "79\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "43\n",
      "80\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "44\n",
      "81\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "44\n",
      "82\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "45\n",
      "83\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "45\n",
      "84\n",
      "\n",
      "Finished with creating the new model and tokenizer\n",
      "Finished Evaluation\n",
      "46\n",
      "85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for index, row in first_set.iterrows():\n",
    "    if (row['lemma'] != \"lemma\"):\n",
    "        total += 1\n",
    "        correct += evaluate_winodict(row)\n",
    "        print(correct)\n",
    "        print(total)\n",
    "        print(\"\")\n",
    "    \n",
    "print(\"GPT-2 Medium achieved a score of: \" + str(float(correct) / float(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0d63-eb8d-429f-af4e-fe2c36f28fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
