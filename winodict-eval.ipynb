{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224N Final Project - Evaluating on WinoDict Dataset\n",
    "By: Christopher Pondoc, Joseph Guman, and Joseph O'Brien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using GPU: \" + str(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in GPT-2 Model\n",
    "Using HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (None)/charset_normalizer (3.0.1) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Winograd Dataset\n",
    "Also taken from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   id     lemma   fake_lemma   pos  tag  \\\n",
      "0                                   0      fear    hydrubous  VERB  VBD   \n",
      "1                                   1  advocate    hydrubous  VERB  VBD   \n",
      "2                                   2     large    ntionessy   ADJ   JJ   \n",
      "3                                   3     small    ntionessy   ADJ   JJ   \n",
      "4                                   4   receive    broinking  VERB  VBN   \n",
      "..                                ...       ...          ...   ...  ...   \n",
      "494  3ZZAYRN1I857UKRI3FD7KHU86YXOTC-2     light  warditedian   ADJ   JJ   \n",
      "495  3ZZAYRN1I857UKRI3FD7KHU973UOTM-1   useless    unduodity   ADJ   JJ   \n",
      "496  3ZZAYRN1I857UKRI3FD7KHU973UOTM-2    useful    unduodity   ADJ   JJ   \n",
      "497  3ZZAYRN1I857UKRI3FD7KHU989DOTI-1    humble        ntury   ADJ   JJ   \n",
      "498  3ZZAYRN1I857UKRI3FD7KHU989DOTI-2  arrogant        ntury   ADJ   JJ   \n",
      "\n",
      "    pronoun                                         definition  \\\n",
      "0      they  The verb to hydrubous means to be afraid or fe...   \n",
      "1      they  The verb to hydrubous means to push for someth...   \n",
      "2        it  The meaning of ntionessy is above average in s...   \n",
      "3        it  The meaning of ntionessy is limited or below a...   \n",
      "4       she  The verb to broinking means to get something; ...   \n",
      "..      ...                                                ...   \n",
      "494       _  The meaning of warditedian is (used of color) ...   \n",
      "495       _  The meaning of unduodity is having no benefici...   \n",
      "496       _  The meaning of unduodity is being of use or se...   \n",
      "497       _  The meaning of ntury is low or inferior in sta...   \n",
      "498       _  The meaning of ntury is having or showing feel...   \n",
      "\n",
      "                                              sentence            option1  \\\n",
      "0    The city councilmen refused the demonstrators ...  The demonstrators   \n",
      "1    The city councilmen refused the demonstrators ...  The demonstrators   \n",
      "2    The trophy doesn't fit into the brown suitcase...       the suitcase   \n",
      "3    The trophy doesn't fit into the brown suitcase...       the suitcase   \n",
      "4    Joan made sure to thank Susan for all the help...              Susan   \n",
      "..                                                 ...                ...   \n",
      "494  Jody wanted new mascara and eyeliner, either b...              black   \n",
      "495  The market was going out of business so they s...               lots   \n",
      "496  The market was going out of business so they s...               lots   \n",
      "497  Derrick greeted Craig at the event but he did ...            Derrick   \n",
      "498  Derrick greeted Craig at the event but he did ...            Derrick   \n",
      "\n",
      "                 option2 label  \n",
      "0    The city councilmen     1  \n",
      "1    The city councilmen     0  \n",
      "2             the trophy     1  \n",
      "3             the trophy     0  \n",
      "4                   Joan     1  \n",
      "..                   ...   ...  \n",
      "494                brown     1  \n",
      "495             products     1  \n",
      "496             products     0  \n",
      "497                Craig     0  \n",
      "498                Craig     1  \n",
      "\n",
      "[499 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "first_set = pd.read_csv(\"winodict/prob1_of_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on One Example\n",
    "Writing a function that is reusable and works for one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_winodict(example):\n",
    "    # First, replace the word with each of the options\n",
    "    if ('_' in example['sentence']):\n",
    "        first_option, second_option = example['sentence'], example['sentence']\n",
    "        pronoun_loc = example['sentence'].index('_')\n",
    "        first_option = example['definition'] + \" \" + first_option[:pronoun_loc] + example['option1'] + first_option[pronoun_loc + 1:]\n",
    "        second_option = example['definition'] + \" \" + second_option[:pronoun_loc] + example['option2'] + second_option[pronoun_loc + 1:]\n",
    "\n",
    "        # Tokenize each string and produce labels\n",
    "        first_inputs, second_inputs = tokenizer(first_option, return_tensors=\"pt\"), tokenizer(second_option, return_tensors=\"pt\")\n",
    "        first_labels, second_labels = torch.clone(first_inputs[\"input_ids\"]), torch.clone(second_inputs[\"input_ids\"])\n",
    "        \n",
    "        # Find positioning of tokens of the underscore to split\n",
    "        start_str, start_ind, end_ind = \"\", -1, -1\n",
    "        original_inputs = tokenizer(example['definition'] + \" \" + example['sentence'], return_tensors=\"pt\")\n",
    "        for i in range(len(original_inputs[\"input_ids\"][0])):\n",
    "            value = original_inputs[\"input_ids\"][0][i]\n",
    "            if (tokenizer.decode(value).strip()) in \"_\":\n",
    "                start_str += tokenizer.decode(value).strip()\n",
    "                if (start_ind == -1):\n",
    "                    start_ind = i\n",
    "                if (start_str == \"_\"):\n",
    "                    end_ind = i\n",
    "                    break\n",
    "            else:\n",
    "                if (end_ind == -1):\n",
    "                    start_ind = -1\n",
    "                    start_str = \"\"\n",
    "        \n",
    "        # Create masked string for first option\n",
    "        original_labels = torch.clone(original_inputs[\"input_ids\"])\n",
    "        first_text_tokens = tokenizer(\" \" + example['option1'], return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "        middle_tensor = torch.full((1, len(first_text_tokens)), -100)\n",
    "        final_first_labels = torch.cat((original_labels[:,0:start_ind], middle_tensor, original_labels[:,end_ind + 1:]), dim=1)\n",
    "\n",
    "        # Create masked string for second option\n",
    "        second_text_tokens = tokenizer(\" \" + example['option2'], return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "        middle_tensor = torch.full((1, len(second_text_tokens)), -100)\n",
    "        final_second_labels = torch.cat((original_labels[:,0:start_ind], middle_tensor, original_labels[:,end_ind + 1:]), dim=1)\n",
    "        \n",
    "        # Evaluate the model on each example and check\n",
    "        first_loss = model(**first_inputs, labels=final_first_labels).loss\n",
    "        second_loss = model(**second_inputs, labels=final_second_labels).loss\n",
    "        \n",
    "        # Write down the correct value and check\n",
    "        if (first_loss < second_loss):\n",
    "            return (int(example['label']) == 0)\n",
    "        else:\n",
    "            return (int(example['label']) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Winograd on GPT-2\n",
    "Looking specifically at `WinoDict`, with the first generated examples and adding in the definition and substituting in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Large achieved a score of: 0.5100401606425703\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for index, row in first_set.iterrows():\n",
    "    if (row['lemma'] != \"lemma\"):\n",
    "        total += 1\n",
    "        correct += evaluate_winodict(row)\n",
    "    \n",
    "print(\"GPT-2 Large achieved a score of: \" + str(float(correct) / float(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
